## 6. 순환 신경망(RNN)
### 6.1 순환 신경망의 기초
- 시계열 데이터 : 시간 흐름에 따라 순차적으로 수집된 데이터 -> 관측값이 시간적 의존성을 가짐
- RNN은 기본적으로 과거의 정보를 기억하면서 새로운 정보를 처리
- CNN이 이미지 데이터의 공간적 특징을 추출하여 학습한다면 RNN은 시계열 데이터의 시간적 특징을 추출하여 학습
- Feed Forward Neural Network : 은닉층에서 활성화 함수를 지난 값은 오직 출력층 방향으로만 향함
- RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 지님
- 은닉 상태 : 순환 신경망의 핵심으로 네트워크 메모리 역할을 함

$$
h_t = \tanh(W_{xh} x_t + W_{hh} h_{t-1} + b)
$$

  - $W_x$: 입력 가중치  
  - $W_h$: 이전 은닉 상태 가중치  
  - $b$: 편향 (bias)
- 순환 신경망의 순전파와 역전파
  - 순전파 : 이전에 얻은 기억을 다음으로 넘김 ex) 나는 -> 밥을 -> 먹었다.
  - 역전파 : 틀린 이유를 과거까지 거슬러 올라가서 찾는 과정 = 출력 → 시간을 거슬러 → 가중치 수정
  - 과거로 갈수록 신호가 점점 약해짐 -> 기울기가 점점 0으로 -> 오래된 정보가 거의 학습이 안 됨
  - 반면에 가중치가 1보다 큰 경우에는 가중치 폭발이 일어남
  - `clip_grad_norm_`을 통해 이미 계산된 기울기를 잘라낼 수 있음
  ### 6.2 고급 순환 신경망 아키텍처
  
